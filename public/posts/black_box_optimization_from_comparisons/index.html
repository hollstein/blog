<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Optimizing black box functions purely from A / B comparisons | blog</title>
<meta name="keywords" content="python, llm, optimization">
<meta name="description" content="Promting or prompt engineering is becoming the new programming paradigm for many NLP tasks. Among other things, it means specifying the prompt for a given task as well as generation parameters such as temperature, top-k or penalty-alpha. This is, in fact, an optimization task over the space of possible prompts, suitable LLMs as well as generation. Some o parameters here are discrete (e.g. top-k) and some are continuous (e.g. temperature). There are ways to directly learn prompts or to fine-tune an LLM on a given task, but this might be more costly and time-consuming compared to simply selecting a set of good enough prompt, LLM and generation parameters (80-20 rule).">
<meta name="author" content="">
<link rel="canonical" href="http://example.org/posts/black_box_optimization_from_comparisons/">
<link crossorigin="anonymous" href="http://example.org/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css" integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://example.org/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://example.org/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://example.org/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://example.org/apple-touch-icon.png">
<link rel="mask-icon" href="http://example.org/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://example.org/posts/black_box_optimization_from_comparisons/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="http://example.org/posts/black_box_optimization_from_comparisons/">
  <meta property="og:site_name" content="blog">
  <meta property="og:title" content="Optimizing black box functions purely from A / B comparisons">
  <meta property="og:description" content="Promting or prompt engineering is becoming the new programming paradigm for many NLP tasks. Among other things, it means specifying the prompt for a given task as well as generation parameters such as temperature, top-k or penalty-alpha. This is, in fact, an optimization task over the space of possible prompts, suitable LLMs as well as generation. Some o parameters here are discrete (e.g. top-k) and some are continuous (e.g. temperature). There are ways to directly learn prompts or to fine-tune an LLM on a given task, but this might be more costly and time-consuming compared to simply selecting a set of good enough prompt, LLM and generation parameters (80-20 rule).">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-06-14T10:27:55+02:00">
    <meta property="article:modified_time" content="2023-06-14T10:27:55+02:00">
    <meta property="article:tag" content="Python">
    <meta property="article:tag" content="Llm">
    <meta property="article:tag" content="Optimization">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Optimizing black box functions purely from A / B comparisons">
<meta name="twitter:description" content="Promting or prompt engineering is becoming the new programming paradigm for many NLP tasks. Among other things, it means specifying the prompt for a given task as well as generation parameters such as temperature, top-k or penalty-alpha. This is, in fact, an optimization task over the space of possible prompts, suitable LLMs as well as generation. Some o parameters here are discrete (e.g. top-k) and some are continuous (e.g. temperature). There are ways to directly learn prompts or to fine-tune an LLM on a given task, but this might be more costly and time-consuming compared to simply selecting a set of good enough prompt, LLM and generation parameters (80-20 rule).">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://example.org/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Optimizing black box functions purely from A / B comparisons",
      "item": "http://example.org/posts/black_box_optimization_from_comparisons/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Optimizing black box functions purely from A / B comparisons",
  "name": "Optimizing black box functions purely from A \/ B comparisons",
  "description": "Promting or prompt engineering is becoming the new programming paradigm for many NLP tasks. Among other things, it means specifying the prompt for a given task as well as generation parameters such as temperature, top-k or penalty-alpha. This is, in fact, an optimization task over the space of possible prompts, suitable LLMs as well as generation. Some o parameters here are discrete (e.g. top-k) and some are continuous (e.g. temperature). There are ways to directly learn prompts or to fine-tune an LLM on a given task, but this might be more costly and time-consuming compared to simply selecting a set of good enough prompt, LLM and generation parameters (80-20 rule).\n",
  "keywords": [
    "python", "llm", "optimization"
  ],
  "articleBody": "Promting or prompt engineering is becoming the new programming paradigm for many NLP tasks. Among other things, it means specifying the prompt for a given task as well as generation parameters such as temperature, top-k or penalty-alpha. This is, in fact, an optimization task over the space of possible prompts, suitable LLMs as well as generation. Some o parameters here are discrete (e.g. top-k) and some are continuous (e.g. temperature). There are ways to directly learn prompts or to fine-tune an LLM on a given task, but this might be more costly and time-consuming compared to simply selecting a set of good enough prompt, LLM and generation parameters (80-20 rule).\nBack to this optimization task: For many instances, there will not be a good metric that one can automatically compute and that is very well aligned with the task at hand. For these cases, manual judgement or labeling will be needed. However, rating outputs consistently on a scale is very difficult and unpractical for many reasons. What should be easy for most humans is to express preference over one outcome versus another one.\nSo, we need an optimization approach that doesn’t act on direct function values but on comparisons given by a human, which is efficient in exploring the parameter space to make best use of human time.\nAfter some research on the current state of the art, I’m settling with botorch which implements methods for this approach. They way to use it is to imports the used libraries:\nfrom botorch.acquisition.preference import AnalyticExpectedUtilityOfBestOption from botorch.models.pairwise_gp import ( PairwiseGP, PairwiseLaplaceMarginalLogLikelihood ) from botorch.models.transforms.input import Normalize from botorch.optim import optimize_acqf from botorch.fit import fit_gpytorch_mll import numpy as np import torch from itertools import combinations from scipy.stats import multivariate_normal import warnings warnings.filterwarnings('ignore') and to give the to be optimized utility function. Here I’m using a toy-example which is a multinomial Gaussian, but in a real application a human would express preferences over generated text:\n# data generating helper functions, not to be called directly :-) def __utility(X): \"\"\"Given X, output corresponding utility (i.e., the latent function)\"\"\" global mn return mn.pdf(X) def compare(xx,ii,jj): \"\"\"Costly eval function here\"\"\" return [ x[0] for x in sorted( [(ii,__utility(xx[ii])),(jj,__utility(xx[jj]))], key=lambda x:x[1],reverse=True ) ] Specify some settings:\nNUM_BATCHES = 15 dim = 2 NUM_RESTARTS = 3 RAW_SAMPLES = 512 q = 2 # number of points per query q_comp = 1 # number of comparisons per query noise = 0.01 And run the optimization loop:\nbounds = torch.stack([torch.zeros(dim), torch.ones(dim)]) # user either one #x_max_unknown = np.random.uniform(low=0,high=1,size=dim) # random center point x_max_unknown = np.array([0.492, 0.53]) # put in center so graph looks nice mn = multivariate_normal(mean=x_max_unknown,cov=.05) print(\"x max:\",x_max_unknown) print() xx = np.random.uniform(low=0,high=1,size=(q,dim)) # initial random dataset comparisons = np.array( [ compare(xx,ii,jj) for ii,jj in list(combinations(range(len(xx)), 2)) ] ) model = PairwiseGP( torch.tensor(xx), torch.tensor(comparisons), input_transform=Normalize(d=xx.shape[-1]), ) x_max_trace=[] with warnings.catch_warnings(): for j in range(1, NUM_BATCHES + 1): next_X, acq_val = optimize_acqf( acq_function=AnalyticExpectedUtilityOfBestOption(pref_model=model), bounds=bounds, q=q, num_restarts=NUM_RESTARTS, raw_samples=RAW_SAMPLES, ) xx = np.concatenate([xx,next_X.numpy()]) comparisons = np.concatenate([ comparisons, np.array([compare(xx,len(xx)-2,len(xx)-1)])] ) model = PairwiseGP( torch.tensor(xx), torch.tensor(comparisons), input_transform=Normalize(d=xx.shape[-1]), ) i_x_max = int(model.utility.argmax()) x_max = model.datapoints[i_x_max].tolist() x_max_trace.append(x_max) if j%2==0: print( f\"j={j:02}: {','.join([f'{j:.3}' for j in x_max])} \" f\"-\u003e {float(model.utility[i_x_max]):.4} \" f\"L2: {((x_max - x_max_unknown)**2).sum():.4f}\" ) This is the expected output:\nx max: [0.492 0.53 ] j=02: 0.385,0.323 -\u003e 0.5722 L2: 0.0543 j=04: 0.359,0.518 -\u003e 0.7756 L2: 0.0179 j=06: 0.538,0.466 -\u003e 0.8494 L2: 0.0063 j=08: 0.514,0.486 -\u003e 0.9426 L2: 0.0025 j=10: 0.514,0.486 -\u003e 1.032 L2: 0.0025 j=12: 0.514,0.486 -\u003e 1.048 L2: 0.0025 j=14: 0.514,0.486 -\u003e 1.101 L2: 0.0025 Visualize what is going on:\nimport plotly.express as px import pandas as pd import plotly.graph_objects as go df = pd.DataFrame( [ { \"x\":pp[0], \"y\":pp[1], \"u\":__utility(pp) } for pp in np.random.uniform(low=0,high=1,size=(1500,dim)) ] ) fig = px.scatter(df, x=\"x\", y=\"y\",color=\"u\") fig.update_layout(xaxis=dict(domain=[0, 1.0]), yaxis=dict(domain=[0.0, 1.0])) x,y = x_max ax,ay = x_max fig.add_annotation( xref=\"x\", yref=\"y\", x=x, y=y, font={\"size\":20}, text=f\"X\", axref=\"x\", ayref=\"y\", ax=ax, ay=ay, arrowhead=2, ) fig.add_trace( go.Scatter(x=[x[0] for x in x_max_trace],y=[x[1] for x in x_max_trace],mode=\"lines\",name=\"opt path\",line={\"width\":5}) ) for ii,(ci,cj) in enumerate(comparisons.tolist()): x,y = xx[ci].tolist() ax,ay = xx[cj].tolist() fig.add_annotation( xref=\"x\", yref=\"y\", x=x, y=y, arrowcolor=\"#BCBBB5\", text=f\"{ii}\", axref=\"x\", ayref=\"y\", ax=ax, ay=ay, arrowhead=2, ) fig.show() We see that the algorithm picks comparison points to update the expected optimum point in parameter space in a quite efficient way.\n",
  "wordCount" : "696",
  "inLanguage": "en",
  "datePublished": "2023-06-14T10:27:55+02:00",
  "dateModified": "2023-06-14T10:27:55+02:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://example.org/posts/black_box_optimization_from_comparisons/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://example.org/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://example.org/" accesskey="h" title="blog (Alt + H)">blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://example.org/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://example.org/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Optimizing black box functions purely from A / B comparisons
    </h1>
    <div class="post-meta"><span title='2023-06-14 10:27:55 +0200 CEST'>June 14, 2023</span>

</div>
  </header> 
  <div class="post-content"><p>Promting or prompt engineering is becoming the new programming paradigm for many NLP tasks. Among other things, it means specifying the prompt for a given task as well as generation parameters such as temperature, top-k or penalty-alpha. This is, in fact, an optimization task over the space of possible prompts, suitable LLMs as well as generation. Some o parameters here are discrete (e.g. top-k) and some are continuous (e.g. temperature). There are ways to directly learn prompts or to fine-tune an LLM on a given task, but this might be more costly and time-consuming compared to simply selecting a set of good enough prompt, LLM and generation parameters (80-20 rule).</p>
<p>Back to this optimization task: For many instances, there will not be a good metric that one can automatically compute and that is very well aligned with the task at hand. For these cases, manual judgement or labeling will be needed. However, rating outputs consistently on a scale is very difficult and unpractical for many reasons. What should be easy for most humans is to express preference over one outcome versus another one.</p>
<p>So, we need an optimization approach that doesn&rsquo;t act on direct function values but on comparisons given by a human, which is efficient in exploring the parameter space to make best use of human time.</p>
<p>After some research on the current state of the art, I&rsquo;m settling with <a href="https://botorch.org/">botorch</a> which implements methods for this approach. They way to use it is to imports the used libraries:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> botorch.acquisition.preference <span style="color:#f92672">import</span> AnalyticExpectedUtilityOfBestOption
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> botorch.models.pairwise_gp <span style="color:#f92672">import</span> (
</span></span><span style="display:flex;"><span>    PairwiseGP, 
</span></span><span style="display:flex;"><span>    PairwiseLaplaceMarginalLogLikelihood
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> botorch.models.transforms.input <span style="color:#f92672">import</span> Normalize
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> botorch.optim <span style="color:#f92672">import</span> optimize_acqf
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> botorch.fit <span style="color:#f92672">import</span> fit_gpytorch_mll
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> itertools <span style="color:#f92672">import</span> combinations
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> multivariate_normal
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> warnings
</span></span><span style="display:flex;"><span>warnings<span style="color:#f92672">.</span>filterwarnings(<span style="color:#e6db74">&#39;ignore&#39;</span>)
</span></span></code></pre></div><p>and to give the to be optimized utility function. Here I&rsquo;m using a toy-example which is a multinomial Gaussian, but in a real application a human would express preferences over generated text:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># data generating helper functions, not to be called directly :-)</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">__utility</span>(X):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Given X, output corresponding utility (i.e., the latent function)&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">global</span> mn
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> mn<span style="color:#f92672">.</span>pdf(X)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compare</span>(xx,ii,jj):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Costly eval function here&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> [
</span></span><span style="display:flex;"><span>        x[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> sorted(
</span></span><span style="display:flex;"><span>            [(ii,__utility(xx[ii])),(jj,__utility(xx[jj]))],
</span></span><span style="display:flex;"><span>            key<span style="color:#f92672">=</span><span style="color:#66d9ef">lambda</span> x:x[<span style="color:#ae81ff">1</span>],reverse<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>    ]
</span></span></code></pre></div><p>Specify some settings:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>NUM_BATCHES <span style="color:#f92672">=</span> <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>dim <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>NUM_RESTARTS <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>RAW_SAMPLES <span style="color:#f92672">=</span> <span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>q <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>  <span style="color:#75715e"># number of points per query</span>
</span></span><span style="display:flex;"><span>q_comp <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#75715e"># number of comparisons per query</span>
</span></span><span style="display:flex;"><span>noise <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>
</span></span></code></pre></div><p>And run the optimization loop:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>bounds <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>stack([torch<span style="color:#f92672">.</span>zeros(dim), torch<span style="color:#f92672">.</span>ones(dim)])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># user either one</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#x_max_unknown = np.random.uniform(low=0,high=1,size=dim)  # random center point</span>
</span></span><span style="display:flex;"><span>x_max_unknown <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">0.492</span>, <span style="color:#ae81ff">0.53</span>])  <span style="color:#75715e"># put in center so graph looks nice</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mn <span style="color:#f92672">=</span> multivariate_normal(mean<span style="color:#f92672">=</span>x_max_unknown,cov<span style="color:#f92672">=</span><span style="color:#ae81ff">.05</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;x max:&#34;</span>,x_max_unknown)
</span></span><span style="display:flex;"><span>print()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>xx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(low<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,high<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,size<span style="color:#f92672">=</span>(q,dim))  <span style="color:#75715e"># initial random dataset</span>
</span></span><span style="display:flex;"><span>comparisons <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(
</span></span><span style="display:flex;"><span>    [
</span></span><span style="display:flex;"><span>        compare(xx,ii,jj)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> ii,jj <span style="color:#f92672">in</span> list(combinations(range(len(xx)), <span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> PairwiseGP(
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>tensor(xx),
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">.</span>tensor(comparisons),
</span></span><span style="display:flex;"><span>    input_transform<span style="color:#f92672">=</span>Normalize(d<span style="color:#f92672">=</span>xx<span style="color:#f92672">.</span>shape[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]),
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>x_max_trace<span style="color:#f92672">=</span>[]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> warnings<span style="color:#f92672">.</span>catch_warnings():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, NUM_BATCHES <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        next_X, acq_val <span style="color:#f92672">=</span> optimize_acqf(
</span></span><span style="display:flex;"><span>            acq_function<span style="color:#f92672">=</span>AnalyticExpectedUtilityOfBestOption(pref_model<span style="color:#f92672">=</span>model),
</span></span><span style="display:flex;"><span>            bounds<span style="color:#f92672">=</span>bounds,
</span></span><span style="display:flex;"><span>            q<span style="color:#f92672">=</span>q,
</span></span><span style="display:flex;"><span>            num_restarts<span style="color:#f92672">=</span>NUM_RESTARTS,
</span></span><span style="display:flex;"><span>            raw_samples<span style="color:#f92672">=</span>RAW_SAMPLES,
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        xx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate([xx,next_X<span style="color:#f92672">.</span>numpy()])
</span></span><span style="display:flex;"><span>        comparisons <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>concatenate([
</span></span><span style="display:flex;"><span>            comparisons, 
</span></span><span style="display:flex;"><span>            np<span style="color:#f92672">.</span>array([compare(xx,len(xx)<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>,len(xx)<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)])]
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        model <span style="color:#f92672">=</span> PairwiseGP(
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>tensor(xx),
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>tensor(comparisons),
</span></span><span style="display:flex;"><span>            input_transform<span style="color:#f92672">=</span>Normalize(d<span style="color:#f92672">=</span>xx<span style="color:#f92672">.</span>shape[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]),
</span></span><span style="display:flex;"><span>        )        
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        i_x_max <span style="color:#f92672">=</span> int(model<span style="color:#f92672">.</span>utility<span style="color:#f92672">.</span>argmax())
</span></span><span style="display:flex;"><span>        x_max <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>datapoints[i_x_max]<span style="color:#f92672">.</span>tolist()
</span></span><span style="display:flex;"><span>        x_max_trace<span style="color:#f92672">.</span>append(x_max)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> j<span style="color:#f92672">%</span><span style="color:#ae81ff">2</span><span style="color:#f92672">==</span><span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            print(
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;j=</span><span style="color:#e6db74">{</span>j<span style="color:#e6db74">:</span><span style="color:#e6db74">02</span><span style="color:#e6db74">}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{</span><span style="color:#e6db74">&#39;,&#39;</span><span style="color:#f92672">.</span>join([<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">{</span>j<span style="color:#e6db74">:</span><span style="color:#e6db74">.3</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span> <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> x_max])<span style="color:#e6db74">}</span><span style="color:#e6db74"> &#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;-&gt;  </span><span style="color:#e6db74">{</span>float(model<span style="color:#f92672">.</span>utility[i_x_max])<span style="color:#e6db74">:</span><span style="color:#e6db74">.4</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> &#34;</span>
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;L2: </span><span style="color:#e6db74">{</span>((x_max <span style="color:#f92672">-</span> x_max_unknown)<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>sum()<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>            )
</span></span></code></pre></div><p>This is the expected output:</p>
<pre tabindex="0"><code class="language-verbose" data-lang="verbose">x max: [0.492 0.53 ]

j=02: 0.385,0.323 -&gt;  0.5722 L2: 0.0543
j=04: 0.359,0.518 -&gt;  0.7756 L2: 0.0179
j=06: 0.538,0.466 -&gt;  0.8494 L2: 0.0063
j=08: 0.514,0.486 -&gt;  0.9426 L2: 0.0025
j=10: 0.514,0.486 -&gt;  1.032 L2: 0.0025
j=12: 0.514,0.486 -&gt;  1.048 L2: 0.0025
j=14: 0.514,0.486 -&gt;  1.101 L2: 0.0025
</code></pre><p>Visualize what is going on:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> plotly.express <span style="color:#66d9ef">as</span> px
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> plotly.graph_objects <span style="color:#66d9ef">as</span> go
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>df <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(
</span></span><span style="display:flex;"><span>    [
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;x&#34;</span>:pp[<span style="color:#ae81ff">0</span>],
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;y&#34;</span>:pp[<span style="color:#ae81ff">1</span>],
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#34;u&#34;</span>:__utility(pp)
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> pp <span style="color:#f92672">in</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(low<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,high<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1500</span>,dim))
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> px<span style="color:#f92672">.</span>scatter(df, x<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;x&#34;</span>, y<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;y&#34;</span>,color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;u&#34;</span>)
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>update_layout(xaxis<span style="color:#f92672">=</span>dict(domain<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1.0</span>]), yaxis<span style="color:#f92672">=</span>dict(domain<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.0</span>]))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>x,y <span style="color:#f92672">=</span> x_max
</span></span><span style="display:flex;"><span>ax,ay <span style="color:#f92672">=</span> x_max
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>add_annotation(
</span></span><span style="display:flex;"><span>    xref<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;x&#34;</span>,
</span></span><span style="display:flex;"><span>    yref<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;y&#34;</span>,
</span></span><span style="display:flex;"><span>    x<span style="color:#f92672">=</span>x,
</span></span><span style="display:flex;"><span>    y<span style="color:#f92672">=</span>y,
</span></span><span style="display:flex;"><span>    font<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#34;size&#34;</span>:<span style="color:#ae81ff">20</span>},
</span></span><span style="display:flex;"><span>    text<span style="color:#f92672">=</span><span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;X&#34;</span>,
</span></span><span style="display:flex;"><span>    axref<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;x&#34;</span>,
</span></span><span style="display:flex;"><span>    ayref<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;y&#34;</span>,
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">=</span>ax,
</span></span><span style="display:flex;"><span>    ay<span style="color:#f92672">=</span>ay,
</span></span><span style="display:flex;"><span>    arrowhead<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>add_trace(
</span></span><span style="display:flex;"><span>    go<span style="color:#f92672">.</span>Scatter(x<span style="color:#f92672">=</span>[x[<span style="color:#ae81ff">0</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_max_trace],y<span style="color:#f92672">=</span>[x[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">for</span> x <span style="color:#f92672">in</span> x_max_trace],mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;lines&#34;</span>,name<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;opt path&#34;</span>,line<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#34;width&#34;</span>:<span style="color:#ae81ff">5</span>})
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ii,(ci,cj) <span style="color:#f92672">in</span> enumerate(comparisons<span style="color:#f92672">.</span>tolist()):
</span></span><span style="display:flex;"><span>    x,y <span style="color:#f92672">=</span> xx[ci]<span style="color:#f92672">.</span>tolist()
</span></span><span style="display:flex;"><span>    ax,ay <span style="color:#f92672">=</span> xx[cj]<span style="color:#f92672">.</span>tolist()
</span></span><span style="display:flex;"><span>    fig<span style="color:#f92672">.</span>add_annotation(
</span></span><span style="display:flex;"><span>        xref<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;x&#34;</span>,
</span></span><span style="display:flex;"><span>        yref<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;y&#34;</span>,
</span></span><span style="display:flex;"><span>        x<span style="color:#f92672">=</span>x,
</span></span><span style="display:flex;"><span>        y<span style="color:#f92672">=</span>y,
</span></span><span style="display:flex;"><span>        arrowcolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;#BCBBB5&#34;</span>,
</span></span><span style="display:flex;"><span>        text<span style="color:#f92672">=</span><span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>ii<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>,
</span></span><span style="display:flex;"><span>        axref<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;x&#34;</span>,
</span></span><span style="display:flex;"><span>        ayref<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;y&#34;</span>,
</span></span><span style="display:flex;"><span>        ax<span style="color:#f92672">=</span>ax,
</span></span><span style="display:flex;"><span>        ay<span style="color:#f92672">=</span>ay,
</span></span><span style="display:flex;"><span>        arrowhead<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>fig<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p>
  
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>



<div id="https://hollstein.github.io/gelerntes/optimization.json" class="plotly" style="height:400px"></div>
<script>
Plotly.d3.json("https://hollstein.github.io/gelerntes/optimization.json", function(err, fig) {
    Plotly.plot('https:\/\/hollstein.github.io\/gelerntes\/optimization.json', fig.data, fig.layout, {responsive: true});
});
</script></p>
<p>We see that the algorithm picks comparison points to update the expected optimum point in parameter space in a quite efficient way.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://example.org/tags/python/">Python</a></li>
      <li><a href="http://example.org/tags/llm/">Llm</a></li>
      <li><a href="http://example.org/tags/optimization/">Optimization</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://example.org/">blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
